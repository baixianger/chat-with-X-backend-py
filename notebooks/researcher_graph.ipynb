{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc88ff4c",
   "metadata": {},
   "source": [
    "Load env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b589229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d801fdd",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6458a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "client = Client()\n",
    "GENERATE_QUERIES_SYSTEM_PROMPT = (\n",
    "    client.pull_prompt(\"langchain-ai/chat-langchain-generate-queries-prompt\")\n",
    "    .messages[0]\n",
    "    .prompt.template\n",
    ")\n",
    "\n",
    "model_dict = {\n",
    "    \"openai/gpt-4o-mini\": \"openai/gpt-4o-mini\",\n",
    "    \"google_genai/gemini-2.0-flash-exp\": \"google_genai/gemini-2.0-flash-exp\",\n",
    "    \"tongyi/qwen3-32b\": \"tongyi/qwen3-32b\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008fdc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated, Literal, Any\n",
    "\n",
    "class GenerateQueriesConfiguration(BaseModel):\n",
    "    \"\"\"The configuration for the query generation tool.\"\"\"\n",
    "    query_model: str = Field(\n",
    "        description=\"The language model used for processing and refining queries. Should be in the form: provider/model-name.\",\n",
    "    )\n",
    "    generate_queries_system_prompt: str = Field(\n",
    "        default=GENERATE_QUERIES_SYSTEM_PROMPT,\n",
    "        description=\"The system prompt used by the researcher to generate queries based on a step in the research plan.\",\n",
    "    )\n",
    "\n",
    "class RetrieveDocumentsConfiguration(BaseModel):\n",
    "    \"\"\"The configuration for the retrieve documents tool.\"\"\"\n",
    "    embedding_model: Annotated[\n",
    "        str,\n",
    "        {\"__template_metadata__\": {\"kind\": \"embeddings\"}},\n",
    "    ] = Field(\n",
    "            default=\"openai/text-embedding-3-small\",\n",
    "            description=\"Name of the embedding model to use. Must be a valid embedding model name.\",\n",
    "        )\n",
    "    retriever_provider: Annotated[\n",
    "        Literal[\"weaviate\", \"chroma\", \"duckdb\", \"supabase\"],\n",
    "        {\"__template_metadata__\": {\"kind\": \"retriever\"}},\n",
    "    ] = Field(\n",
    "        default=\"chroma\",\n",
    "        description=\"The vector store provider to use for retrieval.\",\n",
    "    )\n",
    "    search_kwargs: dict[str, Any] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"Additional keyword arguments to pass to the search function of the retriever.\",\n",
    "        json_schema_extra={ \"example\": {\"k\": 4, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"filter\": {\"source\": \"langgraph\"}}},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d30a781",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fe2cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Any\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated, Optional, Union, Literal\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def reduce_docs(\n",
    "    existing: Optional[list[Document]],\n",
    "    new: Union[\n",
    "        list[Document],\n",
    "        list[dict[str, Any]],\n",
    "        list[str],\n",
    "        str,\n",
    "        Literal[\"delete\"],\n",
    "    ],\n",
    ") -> list[Document]:\n",
    "    \"\"\"Reduce and process documents based on the input type.\n",
    "\n",
    "    This function handles various input types and converts them into a sequence of Document objects.\n",
    "    It also combines existing documents with the new one based on the document ID.\n",
    "\n",
    "    Args:\n",
    "        existing (Optional[Sequence[Document]]): The existing docs in the state, if any.\n",
    "        new (Union[Sequence[Document], Sequence[dict[str, Any]], Sequence[str], str, Literal[\"delete\"]]):\n",
    "            The new input to process. Can be a sequence of Documents, dictionaries, strings, or a single string.\n",
    "    \"\"\"\n",
    "    if new == \"delete\":\n",
    "        return []\n",
    "\n",
    "    existing_list = list(existing) if existing else []\n",
    "    if isinstance(new, str):\n",
    "        return existing_list + [\n",
    "            Document(page_content=new, metadata={\"uuid\": str(uuid.uuid4())})\n",
    "        ]\n",
    "\n",
    "    new_list = []\n",
    "    if isinstance(new, list):\n",
    "        existing_ids = set(doc.metadata.get(\"uuid\") for doc in existing_list)\n",
    "        for item in new:\n",
    "            if isinstance(item, str):\n",
    "                item_id = str(uuid.uuid4())\n",
    "                new_list.append(Document(page_content=item, metadata={\"uuid\": item_id}))\n",
    "                existing_ids.add(item_id)\n",
    "\n",
    "            elif isinstance(item, dict):\n",
    "                metadata = item.get(\"metadata\", {})\n",
    "                item_id = metadata.get(\"uuid\", str(uuid.uuid4()))\n",
    "\n",
    "                if item_id not in existing_ids:\n",
    "                    new_list.append(\n",
    "                        Document(**item, metadata={**metadata, \"uuid\": item_id})\n",
    "                    )\n",
    "                    existing_ids.add(item_id)\n",
    "\n",
    "            elif isinstance(item, Document):\n",
    "                item_id = item.metadata.get(\"uuid\")\n",
    "                if item_id is None:\n",
    "                    item_id = str(uuid.uuid4())\n",
    "                    new_item = item.model_copy(update={\"metadata\": {\"uuid\": item_id}})\n",
    "                else:\n",
    "                    new_item = item\n",
    "\n",
    "                if item_id not in existing_ids:\n",
    "                    new_list.append(new_item)\n",
    "                    existing_ids.add(item_id)\n",
    "\n",
    "    return existing_list + new_list\n",
    "\n",
    "class ResearcherState(BaseModel):\n",
    "    \"\"\"State of the researcher graph / agent.\"\"\"\n",
    "\n",
    "    question: str\n",
    "    \"\"\"A step in the research plan generated by the retriever agent.\"\"\"\n",
    "    queries: list[str] = Field(default_factory=list)\n",
    "    \"\"\"A list of search queries based on the question that the researcher generates.\"\"\"\n",
    "    documents: Annotated[list[Document], reduce_docs] = Field(default_factory=list)\n",
    "    \"\"\"Populated by the retriever. This is a list of documents that the agent can reference.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ddd0f",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58a25e6",
   "metadata": {},
   "source": [
    "### Queries Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784c60f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langsmith import trace\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "def load_chat_model(fully_specified_name: str) -> tuple[BaseChatModel, str, str]:\n",
    "    \"\"\"Load a chat model from a fully specified name.\n",
    "\n",
    "    Args:\n",
    "        fully_specified_name (str): String in the format 'provider/model'.\n",
    "    \"\"\"\n",
    "    if \"/\" in fully_specified_name:\n",
    "        provider, name = fully_specified_name.split(\"/\", maxsplit=1)\n",
    "    else:\n",
    "        provider = \"\"\n",
    "        name = fully_specified_name\n",
    "\n",
    "    model_kwargs = {\"temperature\": 0}\n",
    "    if provider == \"google_genai\":\n",
    "        # google doesn't support system message\n",
    "        model_kwargs[\"convert_system_message_to_human\"] = True\n",
    "    if provider == \"tongyi\":\n",
    "        # init_chat_model doesn't support tongyi\n",
    "        return ChatTongyi(name=name, model_kwargs=model_kwargs), provider, name\n",
    "    return init_chat_model(name, model_provider=provider, **model_kwargs), provider, name\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Response of the generate queries tool.\"\"\"\n",
    "\n",
    "    queries: list[str] = Field(description=\"The list of generated search queries, at most 3.\")\n",
    "\n",
    "\n",
    "async def generate_queries(\n",
    "    state: ResearcherState, *, config: RunnableConfig\n",
    ") -> Response:\n",
    "    \"\"\"Generate search queries based on the question (a step in the research plan).\n",
    "\n",
    "    This function uses a language model to generate diverse search queries to help answer the question.\n",
    "\n",
    "    Args:\n",
    "        state (QuestionState): The current state of the researcher, including the user's question.\n",
    "        config (RunnableConfig): Configuration with the model used to generate queries.\n",
    "\n",
    "    Returns:\n",
    "        Response: A Pydantic model with a 'queries' key containing the list of generated search queries.\n",
    "    \"\"\"\n",
    "\n",
    "    configuration = GenerateQueriesConfiguration.model_validate(config.get(\"configurable\"))\n",
    "    structured_output_kwargs = (\n",
    "        {\"method\": \"function_calling\"} if \"openai\" in configuration.query_model else {}\n",
    "    )\n",
    "    model, provider, name = load_chat_model(configuration.query_model)\n",
    "    model = model.with_structured_output(Response, **structured_output_kwargs)\n",
    "\n",
    "    async with trace(\n",
    "        name=\"generate_queries\",\n",
    "        run_type=\"tool\",\n",
    "        inputs={\"Question\": state.question},\n",
    "        metadata={\n",
    "            \"ls_provider\": provider,\n",
    "            \"ls_model\": name,\n",
    "        }\n",
    "    ) as ls_trace:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": configuration.generate_queries_system_prompt},\n",
    "            {\"role\": \"human\", \"content\": state.question},\n",
    "        ]\n",
    "        response = await model.ainvoke(messages, {\"tags\": [\"langsmith:nostream\"]})\n",
    "        ls_trace.end(outputs={\"queries\": response.queries})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72bb6f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(queries=['What is the capital city of France?', 'France capital information', 'Paris as the capital of France'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config: RunnableConfig = {\n",
    "    \"configurable\": {\n",
    "        \"query_model\": \"openai/gpt-4o-mini\",\n",
    "        \"generate_queries_system_prompt\": GENERATE_QUERIES_SYSTEM_PROMPT,\n",
    "    }\n",
    "}\n",
    "\n",
    "# test generate queries\n",
    "researcher_state = ResearcherState(question=\"What is the capital of France?\")\n",
    "response = generate_queries(researcher_state, config=config)\n",
    "await response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5aa03",
   "metadata": {},
   "source": [
    "### Documents Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43bd092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Any, Iterator\n",
    "from pydantic import BaseModel, Field\n",
    "from contextlib import contextmanager\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.vectorstores.duckdb import DuckDB\n",
    "from langchain_weaviate import WeaviateVectorStore\n",
    "import os\n",
    "import chromadb\n",
    "import duckdb\n",
    "import weaviate\n",
    "# warning: 这三个向量数据库存在和protobuf不兼容的问题，需要固定5.29.0版本\n",
    "\n",
    "class QueryState(BaseModel):\n",
    "    \"\"\"Private state for the retrieve_documents node in the researcher graph.\"\"\"\n",
    "\n",
    "    query: str = Field(description=\"The query string.\")\n",
    "\n",
    "def make_text_encoder(model: str) -> Embeddings:\n",
    "    \"\"\"Connect to the configured text encoder.\"\"\"\n",
    "    provider, model = model.split(\"/\", maxsplit=1)\n",
    "    match provider:\n",
    "        case \"openai\":\n",
    "            from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "            return OpenAIEmbeddings(model=model)\n",
    "        case _:\n",
    "            raise ValueError(f\"Unsupported embedding provider: {provider}\")\n",
    "\n",
    "@contextmanager\n",
    "def make_chroma_retriever(\n",
    "    configuration: RetrieveDocumentsConfiguration, embedding_model: Embeddings\n",
    ") -> Iterator[BaseRetriever]:\n",
    "    \"\"\"Ref: https://python.langchain.com/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html\n",
    "            https://python.langchain.com/docs/integrations/vectorstores/chroma/#running-locally-with-data-persistence-1\"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(\n",
    "        path=os.environ[\"CHROMA_PATH\"],\n",
    "    )\n",
    "    store = Chroma(\n",
    "            client=chroma_client,\n",
    "            collection_name=\"LangChain_Combined_Docs_OpenAI_text_embedding_3_small\",\n",
    "            embedding_function=embedding_model,\n",
    "            persist_directory=os.environ[\"CHROMA_PATH\"],\n",
    "        )\n",
    "    # help(store.as_retriever) # debug\n",
    "    search_kwargs = {**configuration.search_kwargs} # \"return_uuids\" 不支持\n",
    "    retriever = store.as_retriever(search_kwargs=search_kwargs)\n",
    "    try:\n",
    "        yield retriever\n",
    "    finally:\n",
    "        pass \n",
    "\n",
    "@contextmanager\n",
    "def make_weaviate_retriever(\n",
    "    configuration: RetrieveDocumentsConfiguration, embedding_model: Embeddings\n",
    ") -> Iterator[BaseRetriever]:\n",
    "    \"\"\"Ref: https://weaviate-python-client.readthedocs.io/en/latest/weaviate.html#weaviate.connect_to_embedded\"\"\"\n",
    "    with weaviate.connect_to_embedded(\n",
    "        persistence_data_path=os.environ[\"WEAVIATE_PATH\"],\n",
    "        binary_path=os.environ[\"WEAVIATE_PATH\"],\n",
    "        environment_variables={\"LOG_LEVEL\": \"error\"}\n",
    "    ) as weaviate_client:\n",
    "        store = WeaviateVectorStore(\n",
    "            client=weaviate_client,\n",
    "            index_name=\"LangChain_Combined_Docs_OpenAI_text_embedding_3_small\",\n",
    "            text_key=\"text\",\n",
    "            embedding=embedding_model,\n",
    "            attributes=[\"source\", \"title\"],\n",
    "        )\n",
    "        # help(store.as_retriever) # debug\n",
    "        search_kwargs = {**configuration.search_kwargs, \"return_uuids\": True}\n",
    "        yield store.as_retriever(search_kwargs=search_kwargs)\n",
    "\n",
    "@contextmanager\n",
    "def make_duckdb_retriever(\n",
    "    configuration: RetrieveDocumentsConfiguration, embedding_model: Embeddings\n",
    ") -> Iterator[BaseRetriever]:\n",
    "    \"\"\"Ref: https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.duckdb.DuckDB.html\n",
    "            https://duckdb.org/docs/stable/clients/python/overview.html#persistent-storage\"\"\"\n",
    "    with duckdb.connect(\n",
    "        database=os.environ[\"DUCKDB_PATH\"],\n",
    "        config={\n",
    "        # secure configuration\n",
    "            \"enable_external_access\": \"false\",\n",
    "            \"autoinstall_known_extensions\": \"false\",\n",
    "            \"autoload_known_extensions\": \"false\"\n",
    "        }\n",
    "    ) as duckdb_client:\n",
    "        store = DuckDB(\n",
    "            connection=duckdb_client,\n",
    "            table_name=\"LangChain_Combined_Docs_OpenAI_text_embedding_3_small\",\n",
    "            embedding=embedding_model,\n",
    "        )\n",
    "        # help(store.as_retriever) # debug\n",
    "        search_kwargs = {**configuration.search_kwargs, \"return_uuids\": True}\n",
    "        yield store.as_retriever(search_kwargs=search_kwargs)\n",
    "\n",
    "@contextmanager\n",
    "def make_retriever(\n",
    "    config: RunnableConfig,\n",
    ") -> Iterator[BaseRetriever]:\n",
    "    \"\"\"Create a retriever for the agent, based on the current configuration.\"\"\"\n",
    "    configuration = RetrieveDocumentsConfiguration.model_validate(config.get(\"configurable\"))\n",
    "    embedding_model = make_text_encoder(configuration.embedding_model)\n",
    "    match configuration.retriever_provider:\n",
    "        case \"weaviate\":\n",
    "            with make_weaviate_retriever(configuration, embedding_model) as retriever:\n",
    "                yield retriever\n",
    "        case \"chroma\":\n",
    "            with make_chroma_retriever(configuration, embedding_model) as retriever:\n",
    "                yield retriever\n",
    "        case \"duckdb\":\n",
    "            with make_duckdb_retriever(configuration, embedding_model) as retriever:\n",
    "                yield retriever\n",
    "        case _:\n",
    "            raise ValueError(\n",
    "                \"Unrecognized retriever_provider in configuration. \"\n",
    "                f\"Expected one of: {', '.join(BaseConfiguration.__annotations__['retriever_provider'].__args__)}\\n\"\n",
    "                f\"Got: {configuration.retriever_provider}\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc9a4a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "\n",
    "async def retrieve_documents(\n",
    "    state: QueryState, *, config: RunnableConfig\n",
    ") -> dict[str, list[Document]]:\n",
    "    \"\"\"Retrieve documents based on a given query.\n",
    "\n",
    "    This function uses a retriever to fetch relevant documents for a given query.\n",
    "\n",
    "    Args:\n",
    "        state (QueryState): The current state containing the query string.\n",
    "        config (RunnableConfig): Configuration with the retriever used to fetch documents.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, list[Document]]: A dictionary with a 'documents' key containing the list of retrieved documents.\n",
    "    \"\"\"\n",
    "    with make_retriever(config) as retriever:\n",
    "        response = await retriever.ainvoke(state.query, config)\n",
    "        return {\"documents\": response}\n",
    "\n",
    "def retrieve_in_parallel(state: ResearcherState) -> list[Send]:\n",
    "    \"\"\"Create parallel retrieval tasks for each generated query.\n",
    "\n",
    "    This function prepares parallel document retrieval tasks for each query in the researcher's state.\n",
    "\n",
    "    Args:\n",
    "        state (ResearcherState): The current state of the researcher, including the generated queries.\n",
    "\n",
    "    Returns:\n",
    "        Literal[\"retrieve_documents\"]: A list of Send objects, each representing a document retrieval task.\n",
    "\n",
    "    Behavior:\n",
    "        - Creates a Send object for each query in the state.\n",
    "        - Each Send object targets the \"retrieve_documents\" node with the corresponding query.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        Send(\"retrieve_documents\", QueryState(query=query)) for query in state.queries\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf1dc278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"build_git_commit\":\"62dcafac32\",\"build_go_version\":\"go1.24.3\",\"build_image_tag\":\"HEAD\",\"build_wv_version\":\"1.30.5\",\"error\":\"cannot find peer\",\"level\":\"error\",\"msg\":\"transferring leadership\",\"time\":\"2025-07-29T11:20:18+02:00\"}\n",
      "{\"build_git_commit\":\"62dcafac32\",\"build_go_version\":\"go1.24.3\",\"build_image_tag\":\"HEAD\",\"build_wv_version\":\"1.30.5\",\"error\":\"cannot find peer\",\"level\":\"error\",\"msg\":\"transferring leadership\",\"time\":\"2025-07-29T11:20:25+02:00\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'documents': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"build_git_commit\":\"62dcafac32\",\"build_go_version\":\"go1.24.3\",\"build_image_tag\":\"HEAD\",\"build_wv_version\":\"1.30.5\",\"error\":\"cannot find peer\",\"level\":\"error\",\"msg\":\"transferring leadership\",\"time\":\"2025-07-29T11:20:32+02:00\"}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "config: RunnableConfig = {\n",
    "    \"configurable\": {\n",
    "        \"embedding_model\": \"openai/text-embedding-3-small\",\n",
    "        \"retriever_provider\": \"weaviate\",\n",
    "        \"search_kwargs\": {\"k\": 6},\n",
    "    }\n",
    "}\n",
    "\n",
    "# test generate queries\n",
    "researcher_state = ResearcherState(\n",
    "    question=\"What is the capital of France?\", \n",
    "    queries=['What is the capital city of France?', 'France capital information', 'Paris as the capital of France'], \n",
    "    documents=[]\n",
    "    )\n",
    "\n",
    "all_docs = []\n",
    "for query in researcher_state.queries:\n",
    "    result = await retrieve_documents(QueryState(query=query), config=config)\n",
    "    all_docs = reduce_docs(all_docs, result[\"documents\"])\n",
    "\n",
    "final_docs = {\"documents\": all_docs}\n",
    "\n",
    "print(final_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a61e87f",
   "metadata": {},
   "source": [
    "## Define the researcher graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83f197e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "\n",
    "builder = StateGraph(ResearcherState)\n",
    "builder.add_node(generate_queries)\n",
    "builder.add_node(retrieve_documents)\n",
    "builder.add_edge(START, \"generate_queries\")\n",
    "builder.add_conditional_edges(\n",
    "    \"generate_queries\",\n",
    "    retrieve_in_parallel,  # type: ignore\n",
    "    path_map=[\"retrieve_documents\"],\n",
    ")\n",
    "builder.add_edge(\"retrieve_documents\", END)\n",
    "graph = builder.compile()\n",
    "graph.name = \"ResearcherGraph\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "202d74e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
