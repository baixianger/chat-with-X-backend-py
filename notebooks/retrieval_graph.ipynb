{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ccb93e",
   "metadata": {},
   "source": [
    "load env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "828bebda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8161eb70",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d51aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e6bf188",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b829ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Any, Optional, Union, Literal\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def reduce_docs(\n",
    "    existing: Optional[list[Document]],\n",
    "    new: Union[\n",
    "        list[Document],\n",
    "        list[dict[str, Any]],\n",
    "        list[str],\n",
    "        str,\n",
    "        Literal[\"delete\"],\n",
    "    ],\n",
    ") -> list[Document]:\n",
    "    \"\"\"Reduce and process documents based on the input type.\n",
    "\n",
    "    This function handles various input types and converts them into a sequence of Document objects.\n",
    "    It also combines existing documents with the new one based on the document ID.\n",
    "\n",
    "    Args:\n",
    "        existing (Optional[Sequence[Document]]): The existing docs in the state, if any.\n",
    "        new (Union[Sequence[Document], Sequence[dict[str, Any]], Sequence[str], str, Literal[\"delete\"]]):\n",
    "            The new input to process. Can be a sequence of Documents, dictionaries, strings, or a single string.\n",
    "    \"\"\"\n",
    "    if new == \"delete\":\n",
    "        return []\n",
    "\n",
    "    existing_list = list(existing) if existing else []\n",
    "    if isinstance(new, str):\n",
    "        return existing_list + [\n",
    "            Document(page_content=new, metadata={\"uuid\": str(uuid.uuid4())})\n",
    "        ]\n",
    "\n",
    "    new_list = []\n",
    "    if isinstance(new, list):\n",
    "        existing_ids = set(doc.metadata.get(\"uuid\") for doc in existing_list)\n",
    "        for item in new:\n",
    "            if isinstance(item, str):\n",
    "                item_id = str(uuid.uuid4())\n",
    "                new_list.append(Document(page_content=item, metadata={\"uuid\": item_id}))\n",
    "                existing_ids.add(item_id)\n",
    "\n",
    "            elif isinstance(item, dict):\n",
    "                metadata = item.get(\"metadata\", {})\n",
    "                item_id = metadata.get(\"uuid\", str(uuid.uuid4()))\n",
    "\n",
    "                if item_id not in existing_ids:\n",
    "                    new_list.append(\n",
    "                        Document(**item, metadata={**metadata, \"uuid\": item_id})\n",
    "                    )\n",
    "                    existing_ids.add(item_id)\n",
    "\n",
    "            elif isinstance(item, Document):\n",
    "                item_id = item.metadata.get(\"uuid\")\n",
    "                if item_id is None:\n",
    "                    item_id = str(uuid.uuid4())\n",
    "                    new_item = item.model_copy(update={\"metadata\": {\"uuid\": item_id}})\n",
    "                else:\n",
    "                    new_item = item\n",
    "\n",
    "                if item_id not in existing_ids:\n",
    "                    new_list.append(new_item)\n",
    "                    existing_ids.add(item_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "class Router(BaseModel):\n",
    "    logic: str = Field(default=\"\", description=\"The logic of the router.\")\n",
    "    type: Annotated[Literal[\"more-info\", \"langchain\", \"general\"]] = Field(default=\"general\", description=\"The type of the router.\")\n",
    "    \n",
    "\n",
    "class InputState(BaseModel):\n",
    "    messages: Annotated[list[AnyMessage], add_messages] = Field(default_factory=list, description=\"Accumulated messages with unique IDs.\")\n",
    "\n",
    "class AgentState(InputState):\n",
    "    router: Router = Field(default=Router(type=\"general\", logic=\"\"), description=\"Router classification of the user's query.\")\n",
    "    steps: list[str] = Field(default_factory=list, description=\"A list of steps in the research plan.\")\n",
    "    documents: Annotated[list[Document], reduce_docs] = Field(default_factory=list, description=\"Populated by the retriever. This is a list of documents that the agent can reference.\")\n",
    "    answer: str = Field(default=\"\", description=\"Final answer. Useful for evaluations\")\n",
    "    query: str = Field(default=\"\", description=\"The query of the user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a8a71",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6767899",
   "metadata": {},
   "source": [
    "### Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a839898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e92d0302",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc121576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
